{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Model building\nimport torch\nimport torchvision\nimport torchvision.transforms as tf # data augmentation and resizing\nimport torchvision.models as models # to get pretrained models\nimport torch.nn as nn # to build NN, criterion\nimport torch.optim as optim # optimizer\n\n# plotting and evaluation\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import confusion_matrix as conf_mat # performance evaluation\n\n# Datapipe Line\nimport pandas as pd # read csv\nfrom imblearn.over_sampling import RandomOverSampler as ROS # training data oversampling\nfrom sklearn.model_selection import train_test_split # splitting dataframes\nfrom torch.utils.data import Dataset, DataLoader # data pipeline\n\n# utils\nimport numpy as np\nimport os\nimport random\nimport torch.nn.functional as F # softmax\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# Setting device\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# For reproducibility\nRANDOM_SEED = 42 \n\ndef set_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\n\nset_seed(RANDOM_SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-29T09:04:10.675807Z","iopub.execute_input":"2024-03-29T09:04:10.676177Z","iopub.status.idle":"2024-03-29T09:04:10.687677Z","shell.execute_reply.started":"2024-03-29T09:04:10.676148Z","shell.execute_reply":"2024-03-29T09:04:10.686600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 0.001\nbs = 128 # On P100, 512 is okay for resnet32 and resnet50, bs 256 is okay for densenet121 and densenet201\nEPOCHS = 40 # number of training epochs in total\nFT_EPOCHS = 5 # first epochs to fine tune classifier head only, after that end to end finetuning begins\nLR_MIN = 1e-6 # minimum learning rate, below that, early training stopping occurs\n\nhighest_acc = 0.80 # Manually set for now\n\n#Choose CNN backbone\nCNNS = ['resnet34', 'resnet50', 'densenet121', 'densenet201']\nCHOSEN_MODEL = CNNS[2] #desnenet121 performs best\n\n# Flags\nSAVE_CHECKPOINT = True\nSAVE_HIGHEST = True","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:04:12.897228Z","iopub.execute_input":"2024-03-29T09:04:12.897587Z","iopub.status.idle":"2024-03-29T09:04:12.903246Z","shell.execute_reply.started":"2024-03-29T09:04:12.897558Z","shell.execute_reply":"2024-03-29T09:04:12.902336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/hmnist_28_28_RGB.csv')\ndata.head()\nclasses = {0: ('akiec', 'Actinic keratoses'),  \n           1:('bcc' , ' basal cell carcinoma'), \n           2:('bkl', 'benign keratosis-like lesions'), \n           3: ('df', 'dermatofibroma'),\n           4: ('nv', ' melanocytic nevi'), \n           5: ('vasc', ' pyogenic granulomas and hemorrhage'), \n           6: ('mel', 'melanoma'),\n          }\n\nCLASSES = [classes[idx][0] for idx in range(len(classes))] #abbreviated form of classes\nCLASSES_FULL = [classes[idx][1] for idx in range(len(classes))] #Full name of classes\nCLASSES, CLASSES_FULL","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:04:15.420195Z","iopub.execute_input":"2024-03-29T09:04:15.420530Z","iopub.status.idle":"2024-03-29T09:04:18.699536Z","shell.execute_reply.started":"2024-03-29T09:04:15.420505Z","shell.execute_reply":"2024-03-29T09:04:18.698615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we divide the data from the labels to use the train_test_split function, then we will add the labels back to an overall dataframe so it is easy to \n#associate the data with its label \nx = data.drop(labels = 'label', axis = 1) #get image data without labels\ny = data.label #just labels\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42) #split data into training and testing (also shuffles data)\nx_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=1) #split the remaining data into val and test\n\n#we use a 80% train, 10% validation, 10% test split\nprint('% of images used for training: {}%:'.format(100*np.shape(x_train)[0]/10000))\nprint('% of images used for testing: {}%'.format(100*np.shape(x_test)[0]/10000))\nprint('% of images used for validation: {}%'.format(100*np.shape(x_val)[0]/10000))\n\n#randomly oversample the training data to avoid bias in learning process\nrandOvrSamp = ROS()\nx_train, y_train = randOvrSamp.fit_resample(x_train, y_train)\n\n\n#add the labels to the overall training dataframex\n#we copy xtrain here to avoid fragmentation from the previous inserts\nx_train = x_train.copy()\nx_train.insert(0, 'label', value = y_train.values)\ntrainingData = x_train\n\n#add the labels to the overall validation dataframe\nx_val.insert(0, 'label', value = y_val.values)\nvalData = x_val\n\n#add the labels to the overall testing dataframe\nx_test.insert(0, 'label', value = y_test.values)\ntestData = x_test","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:04:20.769470Z","iopub.execute_input":"2024-03-29T09:04:20.769843Z","iopub.status.idle":"2024-03-29T09:04:23.157336Z","shell.execute_reply.started":"2024-03-29T09:04:20.769813Z","shell.execute_reply":"2024-03-29T09:04:23.156505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we only run this cell to calculate the mean and std deviation, we don't need to run it once we know these values\n\n#we'll calculate the mean and std deviation for normalization here:\ntemp = x\n\n#reshape the array to be (# of images * w * l * 3)\ntemp = np.asarray(temp).reshape(-1, 28, 28, 3)/255\n\n#mean\nmean = torch.tensor([np.mean(temp[:,:,:,channel]) for channel in range(3)])\nmean = torch.flatten(mean.reshape(1,3,1,1))\nprint(mean)\n\n#std deviation\nstd = torch.tensor([np.std(temp[:,:,:,channel]) for channel in range(3)])\nstd = torch.flatten(std.reshape(1,3,1,1))\nprint(std)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T09:04:25.842397Z","iopub.execute_input":"2024-03-29T09:04:25.843244Z","iopub.status.idle":"2024-03-29T09:04:26.062953Z","shell.execute_reply.started":"2024-03-29T09:04:25.843210Z","shell.execute_reply":"2024-03-29T09:04:26.061861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the CNN","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, num_classes, model = 'resnet50'):\n        super(CNN, self).__init__()\n        self.num_classes = num_classes\n        \n        self.chosen_model = model\n        if self.chosen_model == 'resnet50':\n            self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n            self.classifier = nn.Sequential(\n                nn.Dropout(0.1),\n                nn.Linear(self.model.fc.in_features, 256, bias=False),\n                nn.ReLU(),\n                nn.BatchNorm1d(256),\n                \n                nn.Linear(256, 256//2, bias=False),\n                nn.ReLU(),\n                nn.BatchNorm1d(256//2),\n                \n                nn.Linear(128, self.num_classes, bias=False),\n                nn.BatchNorm1d(self.num_classes),\n            )\n        self.model.fc = self.classifier\n    def forward(self,x):\n        return self.model(x)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:29:33.092787Z","iopub.execute_input":"2024-03-29T10:29:33.093436Z","iopub.status.idle":"2024-03-29T10:29:33.102208Z","shell.execute_reply.started":"2024-03-29T10:29:33.093408Z","shell.execute_reply":"2024-03-29T10:29:33.101237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HAM10K(Dataset):\n    def __init__(self, dataframe, transforms = None):\n        self.data = dataframe #all data\n        self.y = self.data.label #ground truth\n        self.x = self.data.drop(labels = 'label', axis = 1) #image data ie. input \n        \n        #reshape data to be 28x28 3 channel images\n        self.x = np.asarray(self.x, dtype=np.uint8).reshape(-1, 28,28,3)\n        self.tf = transforms\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        label = torch.tensor(self.y.iloc[idx])\n        img = self.x[idx]\n        img =  Image.fromarray(img, 'RGB')\n        if self.tf != None:\n            img = self.tf(img)\n        return img, label\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:29:37.043694Z","iopub.execute_input":"2024-03-29T10:29:37.044606Z","iopub.status.idle":"2024-03-29T10:29:37.052840Z","shell.execute_reply.started":"2024-03-29T10:29:37.044562Z","shell.execute_reply":"2024-03-29T10:29:37.051893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = tf.Compose(\n    [\n        \n        tf.Resize(232),\n        tf.CenterCrop(224),\n        tf.RandomVerticalFlip(0.5),\n        tf.RandomHorizontalFlip(0.5),\n        tf.RandomRotation(0.2),\n        tf.ToTensor(),\n        tf.Normalize([0.7636, 0.5462, 0.5706], [0.1391, 0.1504, 0.1673])\n    ]\n)\n\nval_transforms = tf.Compose(\n    [\n        tf.Resize(232),\n        tf.CenterCrop(224),\n        tf.ToTensor(),\n        tf.Normalize([0.7636, 0.5462, 0.5706], [0.1391, 0.1504, 0.1673])\n    ]\n\n)\n\ntest_transforms = None\n\n\ntrain_ds = HAM10K(trainingData, train_transforms)\ntrainLoader = DataLoader(train_ds, batch_size = bs, shuffle = True, pin_memory = True, num_workers = 2)\n\nval_ds = HAM10K(valData, train_transforms)\nvalLoader = DataLoader(val_ds, batch_size = bs, shuffle = False, pin_memory = True, num_workers = 2)\n\ntest_ds = HAM10K(testData, train_transforms)\ntestLoader = DataLoader(test_ds, batch_size = bs, shuffle = False, pin_memory = True, num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:03:10.339705Z","iopub.execute_input":"2024-03-29T11:03:10.340555Z","iopub.status.idle":"2024-03-29T11:03:10.659834Z","shell.execute_reply.started":"2024-03-29T11:03:10.340526Z","shell.execute_reply":"2024-03-29T11:03:10.658969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height = 5\nwidth = 5\nfig = plt.figure(figsize = (10,10))\nfor i in range(25):\n    trainim, label= train_ds.__getitem__(i)\n    trainim = trainim.permute(2,1,0)\n    fig.add_subplot(height, width, i+1)\n    plt.imshow(trainim)\n    plt.axis('off')\n    plt.title('Class {}'.format(CLASSES[label]))","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:03:12.821381Z","iopub.execute_input":"2024-03-29T11:03:12.822228Z","iopub.status.idle":"2024-03-29T11:03:14.935656Z","shell.execute_reply.started":"2024-03-29T11:03:12.822196Z","shell.execute_reply":"2024-03-29T11:03:14.934747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training Loop\n","metadata":{}},{"cell_type":"code","source":"model = CNN(len(CLASSES), model = 'resnet50').to(DEVICE)\n\n#freeze all weights\nfor p in model.parameters():\n    p.requires_grad = False\n\n#only want to update the classifier weights\nfor p in model.classifier.parameters():\n    p.requires_grad = True\n\noptimizer = optim.AdamW(model.parameters(), lr = lr, weight_decay = 0.1)\n\ncriterion = nn.CrossEntropyLoss()\nval_criterion = nn.CrossEntropyLoss()\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True) ","metadata":{"execution":{"iopub.status.busy":"2024-03-29T11:03:21.805560Z","iopub.execute_input":"2024-03-29T11:03:21.805889Z","iopub.status.idle":"2024-03-29T11:03:22.287380Z","shell.execute_reply.started":"2024-03-29T11:03:21.805863Z","shell.execute_reply":"2024-03-29T11:03:22.286453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_acc = []\ntrain_losses = []\n\ntest_acc = []\ntest_losses = []\n\nlrs = []\n\n# For warmup\nlr0 = lr*0.01\n\nlr_step = (lr-lr0)/(len(trainLoader)-1) # lr step for slow warm up from lr0 to lr \n\nprint(f'Highest acc to beat: {highest_acc}')\nbest_acc = 0.90*highest_acc # use to decide whether to save a run \n\nfor epoch in range(EPOCHS):\n        loader = tqdm(trainLoader)\n        losses = [] # logs avg loss per epoch\n        accs = [] # logs avg acc per epoch\n        correct = 0 # counts how many correct predictions\n        count = 0 # counts how many samples\n        \n        if epoch>0:\n            lrs+= [optimizer.param_groups[0]['lr']]*len(trainLoader) # track lr after warm up\n        \n        if epoch==FT_EPOCHS:\n            for p in model.parameters():\n                p.requires_grad = True\n            print('End to End Fine Tuning Begins')\n\n        model.train()\n        for bidx, (images, labels) in enumerate(loader):\n            \n            # Warm up, slowly increase fomr lr0 to lr in first epoch\n            if epoch==0:\n                    \n                lr_ = lr0 + lr_step*bidx\n\n                for op in optimizer.param_groups:\n                    op['lr'] = lr_\n\n                lrs.append(optimizer.param_groups[0]['lr']) # track lr\n\n            images = images.to(DEVICE) # move to gpu\n            labels = labels.to(DEVICE)\n                \n            score = model(images)\n            loss = criterion(score, labels)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            with torch.no_grad():\n                pred = torch.argmax(score, -1).detach() # need to detach else bug\n                correct += (pred==labels).sum() # count how many correct\n                count += len(labels)\n                acc = correct/count # accumated accuracy\n                \n                losses.append(loss.item())\n                accs.append(acc)\n                \n                loader.set_description(f'TRAIN | epoch {epoch+1}/{EPOCHS} | acc {acc:.4f} | loss {loss.item():.4f}')\n                \n        train_acc.append(acc)\n        train_losses.append(torch.tensor(losses).mean().item())\n                \n        model.eval()\n        with torch.no_grad():\n            \n            loader = tqdm(valLoader)\n            \n            losses = [] # logs loss per minibatch\n            accs = [] # logs running acc throughout one epoch\n            \n            correct = 0 # counts how many correct predictions in one epoch\n            count = 0 # counts how many samples seen in one epoch\n            \n            for bidx, (images, labels) in enumerate(loader):\n                images = images.to(DEVICE) # move to gpu\n                labels = labels.to(DEVICE)\n\n                score = model(images)\n                loss = val_criterion(score, labels)\n                \n                pred = torch.argmax(score, -1).detach() # need to detach else bug\n                correct += (pred==labels).sum() # count how many correct\n                count += len(labels)\n\n                acc = correct/count # accumated accuracy\n                loader.set_description(f'TEST | epoch {epoch+1}/{EPOCHS} | acc {acc:.4f} | loss {loss.item():.4f}')\n                \n                losses.append(loss.item())\n                accs.append(acc)\n\n        test_acc.append(acc)\n        test_losses.append(torch.tensor(losses).mean().item())\n        \n        scheduler.step(torch.tensor(acc)) # reduce lr if test acc does not improve\n        \n        if SAVE_CHECKPOINT==True:\n            if test_acc[-1]>best_acc:\n                best_acc = test_acc[-1].item()\n\n                checkpoint = {\n                    'model': model,\n                    'losses': [train_losses, test_losses],\n                    'accs': [train_acc, test_acc],\n                    'lrs': lrs,\n                    'best_acc': best_acc,\n                    'last_epoch_trained': epoch,\n                }\n                \n                if best_acc > highest_acc and SAVE_HIGHEST==True:\n                    old_highest_acc = highest_acc\n                    highest_acc = best_acc\n                    torch.save(highest_acc, 'highest_acc.pt')\n                    print(f'HIGHEST ACCURACY SURPASSED from {old_highest_acc} to {highest_acc}') # save highest achieving model evahhh (yayyy! ^.^)\n                    torch.save(checkpoint, f'{highest_acc:.4f} checkpoint.pt')\n\n                torch.save(checkpoint, 'checkpoint.pt')\n                print(f'Checkpointed with {best_acc:.4f} best acc')\n            \n        if optimizer.param_groups[0]['lr']<LR_MIN:\n            print(f'EARLY STOPPING! LR below {LR_MIN}')\n            break","metadata":{"execution":{"iopub.status.busy":"2024-03-29T10:30:13.283259Z","iopub.execute_input":"2024-03-29T10:30:13.284156Z","iopub.status.idle":"2024-03-29T11:02:26.920797Z","shell.execute_reply.started":"2024-03-29T10:30:13.284126Z","shell.execute_reply":"2024-03-29T11:02:26.919331Z"},"trusted":true},"execution_count":null,"outputs":[]}]}